{"data":{"site":{"siteMetadata":{"title":"Blogging!","author":"Agustín Aliaga"}},"markdownRemark":{"id":"056748b0-3835-5e1a-849d-f98608b7b2fe","excerpt":"A couple of years ago I heard for the first time about this new technology\ncalled “Docker”. I was intrigued, because I liked ideas like…","html":"<p><img src=\"https://cdn-images-1.medium.com/max/2000/1*NH_Sd3Kd9lRrdEA80nQvjA.jpeg\"></p>\n<p>A couple of years ago I heard for the first time about this new technology\ncalled “Docker”. I was intrigued, because I liked ideas like isolating\napplication’s environments and I wanted to see how I could apply it to my\nday-to-day work as a software developer. I decided to start reading about it,\nand I also attended some local meet-ups. The thing is… these meet-ups were\nfantastic, but they were more oriented to a systems administrators rather than\ndevelopers. The speakers talked about large production deployment with Docker\nand other tools like OpenShift, Chef, Puppet, Kubernetes, etc. This was actually\nquite awesome, but no exactly what I was looking for.</p>\n<p>First things first: if you don’t know anything about Docker, I’d recommend\nreading the starting guide first, so you understand the main concepts (images,\ncontainers vs VMs, volumes, etc.):\n<a href=\"https://docs.docker.com/get-started/\">https://docs.docker.com/get-started/</a></p>\n<h4>Abstracting away each project’s stack</h4>\n<p>So I gave it a try and started introducing Docker to my workflow. I really\nwanted to see how much I could take from it. I mainly work with web and mobile\napplications so there’s almost always some kind of back-end technology in my\nprojects. In my case, I had to work with Python, Node.js and PHP back-ends. The\nfirst thing I wanted from Docker, was the ability of rapidly swapping\ndevelopment environments, so I could fix a specific bug in a different project\nwith a different tech stack without struggling with environment setup ! If\nyou’re a freelance worker, you probably face this kind of scenarios frequently.</p>\n<p>I started working and created an image for each project encapsulating all\nback-end, front-end, and database dependencies into a single container for each\nproject. Docker never “complained” about my approach and it let me do whatever I\nwanted, even if I wasn’t doing the <strong>best thing</strong>. This proved to me that Docker\nis quite versatile. The thing about **versatile **technologies is that you need\nto dig deeper to really take advantage of it. It is way too easy to do things\nwrong. And this is what I was doing, creating big, monolithic images that had a\nnumber of issues. Soon, I realized that I hadn’t read enough about the best\npractices. After reading <a href=\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/\">this piece of\ndocumentation</a>\nI started to understand how docker applies concepts like infrastructure\nmodularization:</p>\n<blockquote>\n<p>Decoupling applications into multiple containers makes it much easier to scale\nhorizontally and reuse containers. For instance, a web application stack might\nconsist of three separate containers, each with its own unique image, to manage\nthe web application, database, and an in-memory cache in a decoupled manner.</p>\n</blockquote>\n<h4>Modularizing services from the applications</h4>\n<p>I then started using Docker Compose, which is a great native tool to declare\ndifferent “services” (different containers), tipically in a Yaml file. If you\nhaven’t heard of it, basically the idea is that you define in the docker-compose\nfile your application containers and how they run instead of doing this manually\nin a bash command. This means that you define for each container things like\nport binding, environment variable files, ports exposed, volumes, and images,\nbetween others. Altogether, these “services” compose the application that is\ntreated as a whole by the “docker-compose” CLI tool. I had finally isolated all\nmy project’s dependencies, and modularized them into a multi-container docker\napp successfully.</p>\n<p>You should take this note: Don’t expect “docker” and “docker-compose” CLI tools\nto behave exactly the same. Also, read about the differences between starting\nyour application with “docker-compose up” and “docker-compose run”:</p>\n<blockquote>\n<p>Typically, you want <code class=\"language-text\">docker-compose up</code>. Use <code class=\"language-text\">up</code> to start or restart all the\nservices defined in a <code class=\"language-text\">docker-compose.yml</code>. In the default “attached” mode,\nyou’ll see all the logs from all the containers. In “detached” mode (<code class=\"language-text\">-d</code>),\nCompose exits after starting the containers, but the containers continue to run\nin the background.</p>\n</blockquote>\n<blockquote>\n<p>The <code class=\"language-text\">docker-compose run</code> command is for running “one-off” or “adhoc” tasks. It\nrequires the service name you want to run and only starts containers for\nservices that the running service depends on. Use <code class=\"language-text\">run</code> to run tests or perform\nan administrative task such as removing or adding data to a data volume\ncontainer.</p>\n</blockquote>\n<p>I recommend you to read these docs about Compose:</p>\n<ul>\n<li><a href=\"https://docs.docker.com/compose/faq/#whats-the-difference-between-up-run-and-start\">https://docs.docker.com/compose/faq/#whats-the-difference-between-up-run-and-start</a></li>\n<li><a href=\"https://docs.docker.com/compose/overview/#compose-documentation\">https://docs.docker.com/compose/overview/#compose-documentation</a></li>\n</ul>\n<h4>What about using Docker to deploy staging or production environments?</h4>\n<p>This was yet another <strong>fantastic</strong> benefit of using this tool. Not only I can\nrun my app virtualized in a modular and manageable way and not care about the\n{Insert language/framework} version it is using, but also I can <strong>work in an\nenvironment that I know it will be similar to staging or production</strong>, giving me\nmuch confidence of what I’m building. I explicitly say “similar” because of\ncourse there are going to be some differences for security or performance\nreasons.</p>\n<p>To achieve this, I started worked in an automated workflow that looked like\nthis:</p>\n<p>It looked very promising to me. All these tasks were performed from some shell\nscripts <strong>automating</strong> <strong>the deployment process, **making it really easy to\nrapidly push fixes or new features to other environments. However, I was\nrepeating my first mistake. Docker lets you do this without any problem, but it\nis not intended to be used this way. You’re not supposed to pull and build from\nall environments all the time ! Be careful because **image building takes up a\nlot of disk space</strong>.</p>\n<p><span class=\"figcaption_hack\">Example CI workflow</span></p>\n<p>Instead, if you want to achieve some sort of Continuous Integration / Continuous\nDelivery workflow you should start by building and pushing your images to some\nregistry such as Docker Hub. After that, it is up to you or your organization\nhow you’ll build custom pipelines with other services (Jenkins, Github, AWS,\netc.). I may explore some of these options in the future and write about it in a\ndifferent article.</p>\n<h4>From a management point of view</h4>\n<p>In the last months I got to realize that a lot of time is wasted in projects\nwhen the people involved change. Every time a new developer is introduced to a\nteam or project, we are wasting an awful amount of time of both the experienced\ndeveloper and the new one. Sometimes the “ramp-up” process takes days to only be\nable to RUN the application locally, depending on the complexity of course. More\noften, team members use different operating systems, making this task harder.</p>\n<p>With Docker, I think all these things change drastically, making our teams more\ndynamic and fast-moving. The new developer wouldn’t have to care about\ninfrastructure, or environment setup. He/she can start solving real issues very\nsoon, and the “ramp-up” time can be invested in more important things like\nbusiness rules, use cases, application architecture, etc.</p>\n<h4>A note on Mac OS-X</h4>\n<p>I’ve been working on OS-X most of the time, and lately I’ve noticed performance\nissues with some projects that have heavy I/O disk access, especially in mounted\nvolumes. I started to investigate a little further, and found a couple of\narticles/threads that explaining the issue in detail. Basically, there’s a major\ndifference in how Docker runs on Mac compared to GNU/Linux, and how it\nsynchronizes host’s and guest’s filesystems. Consider reading more about it if\nyou or your team members use mac:</p>\n<ul>\n<li><a href=\"https://spin.atomicobject.com/2017/06/20/docker-mac-overcoming-slow-volumes/\">https://spin.atomicobject.com/2017/06/20/docker-mac-overcoming-slow-volumes/</a></li>\n<li><a href=\"https://www.reddit.com/r/docker/comments/59u1b8/why_is_docker_so_slow_on_mac/\">https://www.reddit.com/r/docker/comments/59u1b8/why<em>is</em>docker<em>so</em>slow<em>on</em>mac/</a></li>\n<li><a href=\"https://medium.freecodecamp.org/speed-up-file-access-in-docker-for-mac-fbeee65d0ee7\">https://medium.freecodecamp.org/speed-up-file-access-in-docker-for-mac-fbeee65d0ee7</a></li>\n</ul>\n<h4>Finishing !</h4>\n<p>I hope my experience with Docker gives you some idea of how you could\nincorporate it in your projects as part of your development workflow. From my\nperspective, this is a tool that’s not suitable for every single project, but it\nfits a large amount of them. In spite of being a relatively new and\nfast-evolving technology, I found it to be stable enough to my needs.</p>\n<p>Using Docker makes infrastructure more manageable, and gives you awesome\nbenefits like isolating dependencies, rapidly switching environments, fast\nmoving teams, deployment automation, and “deployment confidence”.</p>\n<ul>\n<li><a href=\"https://medium.com/tag/docker?source=post\">Docker</a></li>\n<li><a href=\"https://medium.com/tag/software-development?source=post\">Software Development</a></li>\n<li><a href=\"https://medium.com/tag/docker-compose?source=post\">Docker Compose</a></li>\n<li><a href=\"https://medium.com/tag/virtualization?source=post\">Virtualization</a></li>\n<li><a href=\"https://medium.com/tag/software-engineering?source=post\">Software Engineering</a></li>\n</ul>\n<h3><a href=\"https://medium.com/@agustin.aliaga\">Agustin Aliaga</a></h3>\n<p>Software Developer</p>","frontmatter":{"title":"How Docker worked for me as a software developer","date":"July 24, 2017"}}},"pageContext":{"slug":"/how-docker-worked-for-me-as-a-software-developer/","previous":{"fields":{"slug":"/js-guide-for-java-devs-part-1/"},"frontmatter":{"title":"JS guide for Java developers: Part 1 — scope, closures, global context, this, and undefined"}},"next":null}}